{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# auto reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# import bc stuff\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import tree\n",
    "from acme import wrappers\n",
    "from dm_control import suite\n",
    "\n",
    "from src.environment import NormilizeActionSpecWrapper, MujocoActionNormalizer\n",
    "from src.bc_net import BCNetworkContinuous, BCNetworkContinuousGaussian\n",
    "from src.sac import GaussianPolicy\n",
    "from src.bc_utils import evaluate_network_mujoco, evaluate_network_mujoco_stochastic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# constants:\n",
    "\n",
    "rollout_path = '../../data/rollouts/cheetah_123456_10000_actnoise080/rollouts.pkl'\n",
    "lr = 3e-4\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "# define the scaling factors\n",
    "MSE_SCALING = 1\n",
    "KL_SCALING = 0.001\n",
    "ENTROPY_SCALING = 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = suite.load(domain_name=\"cheetah\", task_name=\"run\")\n",
    "\n",
    "env = NormilizeActionSpecWrapper(env)\n",
    "env = MujocoActionNormalizer(environment=env, rescale='clip')\n",
    "env = wrappers.SinglePrecisionWrapper(env)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get the dimensionality of the observation_spec after flattening\n",
    "flat_obs = tree.flatten(env.observation_spec())\n",
    "# combine all the shapes\n",
    "obs_dim = sum([item.shape[0] for item in flat_obs])\n",
    "\n",
    "# load the rollouts\n",
    "with open(rollout_path, 'rb') as f:\n",
    "    rollouts = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# initialize the network\n",
    "# network = BCNetworkContinuousGaussian(obs_dim, env.action_spec().shape[0])\n",
    "\n",
    "network = GaussianPolicy(obs_dim, env.action_spec().shape[0], hidden_dim=256)\n",
    "\n",
    "guide_dist = torch.distributions.Normal(torch.zeros(env.action_spec().shape[0]), torch.ones(env.action_spec().shape[0]))\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "# define the loss function for reparmetrization trick\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "\n",
    "# define the number of epochs\n",
    "num_epochs = epochs\n",
    "\n",
    "# define the batch size\n",
    "batch_size = batch_size\n",
    "\n",
    "# define the number of batches\n",
    "num_batches = len(rollouts.obs) // batch_size\n",
    "\n",
    "# convert the data to tensors\n",
    "obs = torch.tensor(rollouts.obs, dtype=torch.float32).squeeze()\n",
    "action = torch.tensor(rollouts.action, dtype=torch.float32).squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train the network with reparametrization trick\n",
    "\n",
    "total_mse_loss_arr = []\n",
    "total_kl_div_arr = []\n",
    "total_entropy_loss_arr = []\n",
    "total_loss_arr = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_mse_loss_arr = []\n",
    "    epoch_kl_div_arr = []\n",
    "    epoch_entropy_loss_arr = []\n",
    "    epoch_loss_arr = []\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "        # get the batch\n",
    "        batch_obs = obs[batch * batch_size:(batch + 1) * batch_size]\n",
    "        batch_action = action[batch * batch_size:(batch + 1) * batch_size]\n",
    "\n",
    "        # print(batch_obs.shape)\n",
    "\n",
    "        # sample from the network\n",
    "        sampled_action, log_prob, mean = network.sample(batch_obs)\n",
    "\n",
    "        # compute the mse loss\n",
    "        mse_loss = mse_loss_fn(sampled_action, batch_action)\n",
    "\n",
    "        # compute the kl divergence\n",
    "        guide_log_prob = guide_dist.log_prob(sampled_action)\n",
    "        kl_div = torch.mean(log_prob - guide_log_prob)\n",
    "\n",
    "        # compute the entropy\n",
    "        entropy = torch.mean(-log_prob)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = mse_loss*MSE_SCALING + kl_div*KL_SCALING + entropy*ENTROPY_SCALING\n",
    "\n",
    "        # backpropagate the loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # log the losses\n",
    "        epoch_mse_loss_arr.append(mse_loss.detach().cpu().item())\n",
    "        epoch_kl_div_arr.append(kl_div.detach().cpu().item())\n",
    "        epoch_entropy_loss_arr.append(entropy.detach().cpu().item())\n",
    "        epoch_loss_arr.append(loss.detach().cpu().item())\n",
    "\n",
    "    # log the losses\n",
    "    total_mse_loss_arr.append(np.mean(epoch_mse_loss_arr))\n",
    "    total_kl_div_arr.append(np.mean(epoch_kl_div_arr))\n",
    "    total_entropy_loss_arr.append(np.mean(epoch_entropy_loss_arr))\n",
    "    total_loss_arr.append(np.mean(epoch_loss_arr))\n",
    "\n",
    "    # print the loss\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {loss.item():.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save the network\n",
    "loss_names = ['mse', 'kl', 'entropy']\n",
    "loss_name_portion = '_'.join(loss_names)\n",
    "# from rollout_path, get the dataset name\n",
    "dataset_name = rollout_path.split('/')[-2]\n",
    "model_filename = f'../../data/models/bc_{dataset_name}_{loss_name_portion}.pt'\n",
    "print('saving model to: ', model_filename)\n",
    "# save the network\n",
    "torch.save(network.state_dict(), model_filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 686.3048532171321 Num episodes: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": "686.3048532171321"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the network\n",
    "evaluate_network_mujoco_stochastic(network, env, num_episodes=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the distribution of the kl_div, mse_loss, entropy_loss, loss with shared x axis\n",
    "fig, axs = plt.subplots(4, 1, sharex=True, figsize=(8, 8*4))\n",
    "axs[0].plot(total_mse_loss_arr)\n",
    "axs[0].set_title('MSE Loss')\n",
    "axs[1].plot(total_kl_div_arr)\n",
    "axs[1].set_title('KL Divergence')\n",
    "axs[2].plot(total_entropy_loss_arr)\n",
    "axs[2].set_title('Entropy Loss')\n",
    "axs[3].plot(total_loss_arr)\n",
    "axs[3].set_title('Total Loss')\n",
    "\n",
    "# label x axis\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "# ensure at least 5 ticks on each y axis for each of the subplots\n",
    "for ax in axs:\n",
    "    ax.locator_params(axis='y', nbins=5)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot kl_div and flipped entropy_loss\n",
    "plt.plot(total_kl_div_arr)\n",
    "plt.plot(-np.array(total_entropy_loss_arr))\n",
    "plt.legend(['KL Divergence', 'Entropy Loss'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train with mse and entropy loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# initialize the network\n",
    "# network = BCNetworkContinuousGaussian(obs_dim, env.action_spec().shape[0])\n",
    "\n",
    "network = GaussianPolicy(obs_dim, env.action_spec().shape[0], hidden_dim=256)\n",
    "\n",
    "guide_dist = torch.distributions.Normal(torch.zeros(env.action_spec().shape[0]), torch.ones(env.action_spec().shape[0]))\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "# define the loss function for reparmetrization trick\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "\n",
    "# define the number of epochs\n",
    "num_epochs = epochs\n",
    "\n",
    "# define the batch size\n",
    "batch_size = batch_size\n",
    "\n",
    "# define the number of batches\n",
    "num_batches = len(rollouts.obs) // batch_size\n",
    "\n",
    "# convert the data to tensors\n",
    "obs = torch.tensor(rollouts.obs, dtype=torch.float32).squeeze()\n",
    "action = torch.tensor(rollouts.action, dtype=torch.float32).squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train the network with reparametrization trick\n",
    "\n",
    "total_mse_loss_arr = []\n",
    "# total_kl_div_arr = []\n",
    "total_entropy_loss_arr = []\n",
    "total_loss_arr = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_mse_loss_arr = []\n",
    "    # epoch_kl_div_arr = []\n",
    "    epoch_entropy_loss_arr = []\n",
    "    epoch_loss_arr = []\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "        # get the batch\n",
    "        batch_obs = obs[batch * batch_size:(batch + 1) * batch_size]\n",
    "        batch_action = action[batch * batch_size:(batch + 1) * batch_size]\n",
    "\n",
    "        # print(batch_obs.shape)\n",
    "\n",
    "        # sample from the network\n",
    "        sampled_action, log_prob, mean = network.sample(batch_obs)\n",
    "\n",
    "        # compute the mse loss\n",
    "        mse_loss = mse_loss_fn(sampled_action, batch_action)\n",
    "\n",
    "        # # compute the kl divergence\n",
    "        # guide_log_prob = guide_dist.log_prob(sampled_action)\n",
    "        # kl_div = torch.mean(log_prob - guide_log_prob)\n",
    "\n",
    "        # compute the entropy\n",
    "        entropy = torch.mean(-log_prob)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = mse_loss*MSE_SCALING + entropy*ENTROPY_SCALING\n",
    "\n",
    "        # backpropagate the loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # log the losses\n",
    "        epoch_mse_loss_arr.append(mse_loss.detach().cpu().item())\n",
    "        # epoch_kl_div_arr.append(kl_div.detach().cpu().item())\n",
    "        epoch_entropy_loss_arr.append(entropy.detach().cpu().item())\n",
    "        epoch_loss_arr.append(loss.detach().cpu().item())\n",
    "\n",
    "    # log the losses\n",
    "    total_mse_loss_arr.append(np.mean(epoch_mse_loss_arr))\n",
    "    # total_kl_div_arr.append(np.mean(epoch_kl_div_arr))\n",
    "    total_entropy_loss_arr.append(np.mean(epoch_entropy_loss_arr))\n",
    "    total_loss_arr.append(np.mean(epoch_loss_arr))\n",
    "\n",
    "    # print the loss\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {loss.item():.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save the network\n",
    "loss_names = ['mse', 'entropy']\n",
    "loss_name_portion = '_'.join(loss_names)\n",
    "# from rollout_path, get the dataset name\n",
    "dataset_name = rollout_path.split('/')[-2]\n",
    "model_filename = f'../../data/models/bc_{dataset_name}_{loss_name_portion}.pt'\n",
    "print('saving model to: ', model_filename)\n",
    "# save the network\n",
    "torch.save(network.state_dict(), model_filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "evaluate_network_mujoco_stochastic(network, env, num_episodes=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the distribution of the mse_loss, entropy_loss, loss with shared x axis\n",
    "fig, axs = plt.subplots(3, 1, sharex=True, figsize=(8, 8*3))\n",
    "axs[0].plot(total_mse_loss_arr)\n",
    "axs[0].set_title('MSE Loss')\n",
    "axs[1].plot(total_entropy_loss_arr)\n",
    "axs[1].set_title('Entropy Loss')\n",
    "axs[2].plot(total_loss_arr)\n",
    "axs[2].set_title('Total Loss')\n",
    "\n",
    "# label x axis\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "# ensure at least 5 ticks on each y axis for each of the subplots\n",
    "for ax in axs:\n",
    "    ax.locator_params(axis='y', nbins=5)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### train with just entropy loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}