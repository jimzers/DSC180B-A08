{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MUJOCO_GL=glfw\n",
      "env: PYOPENGL_PLATFORM=\n",
      "env: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
      "Checking that the dm_control installation succeeded...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../src')\n",
    "\n",
    "#Run to install MuJoCo and `dm_control`\n",
    "import distutils.util\n",
    "import subprocess\n",
    "\n",
    "# Use egl locally\n",
    "%env MUJOCO_GL=glfw\n",
    "# Use osmesa on DSMLP\n",
    "# %env MUJOCO_GL=osmesa\n",
    "%env PYOPENGL_PLATFORM=\n",
    "%env PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "\n",
    "print('Checking that the dm_control installation succeeded...')\n",
    "try:\n",
    "    from dm_control import suite\n",
    "    env = suite.load('cartpole', 'swingup')\n",
    "    pixels = env.physics.render()\n",
    "except Exception as e:\n",
    "    raise e from RuntimeError(\n",
    "      'Something went wrong during installation. Check the shell output above '\n",
    "      'for more information.\\n'\n",
    "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
    "      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
    "else:\n",
    "    del pixels, suite\n",
    "\n",
    "\n",
    "#All `dm_control` imports required for this tutorial\n",
    "\n",
    "# The basic mujoco wrapper.\n",
    "from dm_control import mujoco\n",
    "\n",
    "# Access to enums and MuJoCo library functions.\n",
    "from dm_control.mujoco.wrapper.mjbindings import enums\n",
    "from dm_control.mujoco.wrapper.mjbindings import mjlib\n",
    "\n",
    "# PyMJCF\n",
    "from dm_control import mjcf\n",
    "\n",
    "# Composer high level imports\n",
    "from dm_control import composer\n",
    "from dm_control.composer.observation import observable\n",
    "from dm_control.composer import variation\n",
    "\n",
    "# Imports for Composer tutorial example\n",
    "from dm_control.composer.variation import distributions\n",
    "from dm_control.composer.variation import noises\n",
    "from dm_control.locomotion.arenas import floors\n",
    "\n",
    "# Control Suite\n",
    "from dm_control import suite\n",
    "\n",
    "# Run through corridor example\n",
    "from dm_control.locomotion.walkers import cmu_humanoid\n",
    "from dm_control.locomotion.arenas import corridors as corridor_arenas\n",
    "from dm_control.locomotion.tasks import corridors as corridor_tasks\n",
    "\n",
    "# # Soccer\n",
    "# from dm_control.locomotion import soccer\n",
    "\n",
    "# Manipulation\n",
    "from dm_control import manipulation\n",
    "\n",
    "#@title Other imports and helper functions\n",
    "\n",
    "# General\n",
    "import copy\n",
    "import os\n",
    "import itertools\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "\n",
    "# Graphics-related\n",
    "import matplotlib\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import PIL.Image\n",
    "# Internal loading of video libraries.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from torch.optim import Adam\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# try out the wrappers\n",
    "from acme import wrappers\n",
    "from dm_control import suite\n",
    "from acme import wrappers\n",
    "from model import *\n",
    "from utils import *\n",
    "from analysis import *\n",
    "# Soft-Actor-Critic Model\n",
    "from sac import *\n",
    "from replay_memory import *\n",
    "import argparse\n",
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "# Use svg backend for figure rendering\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# Font sizes\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 12\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# Inline video helper function\n",
    "if os.environ.get('COLAB_NOTEBOOK_TEST', False):\n",
    "  # We skip video generation during tests, as it is quite expensive.\n",
    "  display_video = lambda *args, **kwargs: None\n",
    "else:\n",
    "  def display_video(frames, framerate=30):\n",
    "    height, width, _ = frames[0].shape\n",
    "    dpi = 70\n",
    "    orig_backend = matplotlib.get_backend()\n",
    "    matplotlib.use('Agg')  # Switch to headless 'Agg' to inhibit figure rendering.\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(width / dpi, height / dpi), dpi=dpi)\n",
    "    matplotlib.use(orig_backend)  # Switch back to the original backend.\n",
    "    ax.set_axis_off()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_position([0, 0, 1, 1])\n",
    "    im = ax.imshow(frames[0])\n",
    "    def update(frame):\n",
    "      im.set_data(frame)\n",
    "      return [im]\n",
    "    interval = 1000/framerate\n",
    "    anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n",
    "                                   interval=interval, blit=True, repeat=False)\n",
    "    return HTML(anim.to_html5_video())\n",
    "\n",
    "# Seed numpy's global RNG so that cell outputs are deterministic. We also try to\n",
    "# use RandomState instances that are local to a single cell wherever possible.\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "######  Environment wrappers  ####\n",
    "from dm_env import specs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "#@title Loading and simulating a `suite` task{vertical-output: true}\n",
    "\n",
    "# Load the environment\n",
    "# random_state = np.random.RandomState(42)\n",
    "# env = suite.load('hopper', 'stand', task_kwargs={'random': random_state})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from ../data/models/sac_checkpoint_walker_walk_batch512_hidden1024_1123_500\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb Cell 3\u001b[0m in \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#W2sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# load checkpoint - UPLOAD YOUR FILE HERE!\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#W2sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../data/models/sac_checkpoint_walker_walk_batch512_hidden1024_1123_500\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#W2sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m agent\u001b[39m.\u001b[39;49mload_checkpoint(model_path, evaluate\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#W2sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# pull out model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#W2sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m model \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mpolicy\n",
      "File \u001b[0;32m~/DSC180B-A08/visualizations/../src/sac.py:369\u001b[0m, in \u001b[0;36mSAC.load_checkpoint\u001b[0;34m(self, ckpt_path, evaluate)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLoading models from \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(ckpt_path))\n\u001b[1;32m    368\u001b[0m \u001b[39mif\u001b[39;00m ckpt_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 369\u001b[0m     checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(ckpt_path)\n\u001b[1;32m    370\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39m\u001b[39mpolicy_state_dict\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    371\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39m\u001b[39mcritic_state_dict\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/serialization.py:712\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m             opened_file\u001b[39m.\u001b[39mseek(orig_position)\n\u001b[1;32m    711\u001b[0m             \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(opened_file)\n\u001b[0;32m--> 712\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    713\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/serialization.py:1049\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1047\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1048\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1049\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1051\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1053\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/serialization.py:1019\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m loaded_storages:\n\u001b[1;32m   1018\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1019\u001b[0m     load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1021\u001b[0m \u001b[39mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/serialization.py:1001\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m    997\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39m_UntypedStorage)\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_untyped()\n\u001b[1;32m    998\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[39m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m loaded_storages[key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39m_TypedStorage(\n\u001b[0;32m-> 1001\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1002\u001b[0m     dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    174\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 175\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    176\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/serialization.py:152\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    151\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 152\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    153\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    154\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/serialization.py:136\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> 136\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    139\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    140\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# load the environment\n",
    "env = suite.load(domain_name=\"walker\", task_name=\"walk\")\n",
    "# add wrappers onto the environment\n",
    "env = NormilizeActionSpecWrapper(env)\n",
    "env = MujocoActionNormalizer(environment=env, rescale='clip')\n",
    "env = wrappers.SinglePrecisionWrapper(env)\n",
    "\n",
    "\n",
    "\n",
    "class Args:\n",
    "    env_name = 'whatever'\n",
    "    policy = 'Gaussian'\n",
    "    eval = True\n",
    "    gamma = 0.99\n",
    "    tau = 0.005\n",
    "    lr = 0.0003\n",
    "    alpha = 0.2\n",
    "    automatic_entropy_tuning = True\n",
    "    seed = 42\n",
    "    batch_size = 512\n",
    "    num_steps = 1000000\n",
    "    hidden_size = 1024\n",
    "    updates_per_step = 1\n",
    "    start_steps = 10000\n",
    "    target_update_interval = 1\n",
    "    replay_size = 1000000\n",
    "    # use the cuda to speedup\n",
    "    # change back to True\n",
    "    cuda = False\n",
    "\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# get the dimensionality of the observation_spec after flattening\n",
    "flat_obs = tree.flatten(env.observation_spec())\n",
    "# combine all the shapes\n",
    "# obs_dim = sum([item.shape[0] for item in flat_obs])\n",
    "obs_dim = 0\n",
    "for i in flat_obs:\n",
    "    try:\n",
    "        obs_dim += i.shape[0]\n",
    "    except IndexError:\n",
    "        obs_dim += 1\n",
    "\n",
    "# setup agent, using Soft-Actor-Critic Model\n",
    "agent = SAC(obs_dim, env.action_spec(), args)\n",
    "\n",
    "# load checkpoint - UPLOAD YOUR FILE HERE!\n",
    "model_path = '../data/models/sac_checkpoint_walker_walk_batch512_hidden1024_1123_500'\n",
    "agent.load_checkpoint(model_path, evaluate=True)\n",
    "\n",
    "# pull out model\n",
    "model = agent.policy\n",
    "# setup hook dict\n",
    "hook_dict = init_hook_dict(model)\n",
    "# add hooks\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        print(name, module)\n",
    "        module.register_forward_hook(recordtodict_hook(name=name, hook_dict=hook_dict))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run a few episodes just to collect activations\n",
    "num_episodes_to_run = 10\n",
    "\n",
    "for i in range(num_episodes_to_run):\n",
    "    time_step = env.reset()\n",
    "    episode_reward = 0\n",
    "    while not time_step.last():  # or env.get_termination()\n",
    "        # get the state\n",
    "        state = get_flat_obs(time_step)\n",
    "        # sample an action\n",
    "        action = agent.select_action(state)\n",
    "        time_step = env.step(action)\n",
    "\n",
    "        # record reward\n",
    "        episode_reward += time_step.reward\n",
    "    print('Episode: {} Reward: {}'.format(i, episode_reward))\n",
    "\n",
    "\n",
    "loaded_hook_dict = compile_hook_dict(hook_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear1': array([[-6.8759375 , -2.8605616 , -1.444497  , ..., -6.994977  ,\n",
       "         -6.8835955 , -2.4706955 ],\n",
       "        [-6.696662  , -2.6345003 , -2.4793224 , ..., -7.2650023 ,\n",
       "         -7.183061  , -2.8710303 ],\n",
       "        [-6.4651814 , -1.6831925 , -3.2931583 , ..., -7.6537094 ,\n",
       "         -6.6675615 , -2.552099  ],\n",
       "        ...,\n",
       "        [-7.6156006 , -0.540197  ,  1.5038731 , ..., -4.055515  ,\n",
       "         -1.9945788 , -1.2136353 ],\n",
       "        [-7.880992  , -0.8038175 ,  1.2165027 , ..., -4.355412  ,\n",
       "         -2.454401  , -0.81706166],\n",
       "        [-7.591051  ,  0.08079767,  0.6727779 , ..., -2.6759193 ,\n",
       "         -2.1241593 ,  1.2181046 ]], dtype=float32),\n",
       " 'linear2': array([[ -1.709836  ,  -0.44688916,  -4.6141815 , ...,  -1.3566346 ,\n",
       "          -0.69607514,  -0.84597135],\n",
       "        [ -1.5938685 ,  -0.53591204,  -4.1461873 , ...,  -1.2900822 ,\n",
       "          -0.25508887,  -0.72691554],\n",
       "        [ -1.4069092 ,  -0.7056582 ,  -4.2515135 , ...,  -1.2056012 ,\n",
       "           0.23017168,  -0.6264884 ],\n",
       "        ...,\n",
       "        [ -1.1802135 ,  -1.0592124 ,   0.26118773, ...,  -0.9296962 ,\n",
       "          -9.2711315 ,  -0.9273014 ],\n",
       "        [ -1.2221044 ,  -0.87014806,  -0.6060044 , ...,  -0.84787667,\n",
       "          -7.961827  ,  -0.82184005],\n",
       "        [ -1.2841921 ,  -1.2558799 ,   0.94012785, ...,  -0.8870397 ,\n",
       "         -12.096057  ,  -1.0479367 ]], dtype=float32),\n",
       " 'mean_linear': array([[ 0.6557162 ,  0.18083037, -0.06635019, -1.2160137 , -1.1465454 ,\n",
       "          0.09704074],\n",
       "        [ 0.657395  ,  0.27609244, -0.04790933, -0.92423373, -1.1110586 ,\n",
       "         -0.0333012 ],\n",
       "        [ 1.2064267 ,  0.10476121,  0.2154019 , -0.695186  , -0.9359287 ,\n",
       "          0.12686357],\n",
       "        ...,\n",
       "        [-0.82751137,  0.31950945, -0.04641785, -0.19320789,  0.03670925,\n",
       "          0.03979267],\n",
       "        [-0.99479103,  0.8561206 , -0.33217812, -0.23194383,  0.22078107,\n",
       "         -0.0848917 ],\n",
       "        [-1.2712415 ,  0.70082647, -0.16865312, -0.12872288,  0.4252435 ,\n",
       "          0.2647189 ]], dtype=float32),\n",
       " 'log_std_linear': array([[-0.41951725, -0.24287878, -0.33048463, -0.4509772 , -0.40893126,\n",
       "         -0.3181976 ],\n",
       "        [-0.42254543, -0.24637228, -0.3154244 , -0.41079497, -0.3973918 ,\n",
       "         -0.31680334],\n",
       "        [-0.52236485, -0.3455332 , -0.3129393 , -0.42901605, -0.4049927 ,\n",
       "         -0.34997368],\n",
       "        ...,\n",
       "        [-0.44541433, -0.41712907, -0.17642835, -0.2725385 , -0.40033823,\n",
       "         -0.17490263],\n",
       "        [-0.43002367, -0.4774494 , -0.16533114, -0.24140726, -0.40277922,\n",
       "         -0.18451875],\n",
       "        [-0.52010536, -0.45079777, -0.17888726, -0.48293513, -0.4342229 ,\n",
       "         -0.26123774]], dtype=float32)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_hook_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib/axes/_base.py:3270: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  left, right = sorted([left, right], reverse=reverse)\n",
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib/axes/_base.py:3652: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  bottom, top = sorted([bottom, top], reverse=reverse)\n",
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib/axes/_base.py:3652: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  bottom, top = sorted([bottom, top], reverse=reverse)\n",
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib/axes/_base.py:3270: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  left, right = sorted([left, right], reverse=reverse)\n",
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib/axes/_base.py:3652: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  bottom, top = sorted([bottom, top], reverse=reverse)\n",
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib/axes/_base.py:3270: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  left, right = sorted([left, right], reverse=reverse)\n",
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib/axes/_base.py:3652: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  bottom, top = sorted([bottom, top], reverse=reverse)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a558aad0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cka_online = {'activation_1': [],\n",
    "                'activation_2': [],\n",
    "                'cka': []}\n",
    "\n",
    "# get combinations between activations\n",
    "for activation1 in loaded_hook_dict.keys():\n",
    "    for activation2 in loaded_hook_dict.keys():\n",
    "        cka_calc = cka(loaded_hook_dict[activation1], loaded_hook_dict[activation2])\n",
    "        # if activation1 == activation2:\n",
    "        #     cka_calc = 1\n",
    "        cka_online['cka'].append(cka_calc)\n",
    "        cka_online['activation_1'].append(activation1)\n",
    "        cka_online['activation_2'].append(activation2)\n",
    "\n",
    "df = pd.DataFrame(cka_online).pivot('activation_1', 'activation_2', 'cka')\n",
    "sns.heatmap(df, annot=True, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>activation_2</th>\n",
       "      <th>linear1</th>\n",
       "      <th>linear2</th>\n",
       "      <th>log_std_linear</th>\n",
       "      <th>mean_linear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation_1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433177</td>\n",
       "      <td>0.351762</td>\n",
       "      <td>0.178705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear2</th>\n",
       "      <td>0.433177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127477</td>\n",
       "      <td>0.083802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_std_linear</th>\n",
       "      <td>0.351762</td>\n",
       "      <td>0.127477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.198995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_linear</th>\n",
       "      <td>0.178705</td>\n",
       "      <td>0.083802</td>\n",
       "      <td>0.198995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "activation_2     linear1   linear2  log_std_linear  mean_linear\n",
       "activation_1                                                   \n",
       "linear1         1.000000  0.433177        0.351762     0.178705\n",
       "linear2         0.433177  1.000000        0.127477     0.083802\n",
       "log_std_linear  0.351762  0.127477        1.000000     0.198995\n",
       "mean_linear     0.178705  0.083802        0.198995     1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianPolicy(\n",
       "  (linear1): Linear(in_features=24, out_features=1024, bias=True)\n",
       "  (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (mean_linear): Linear(in_features=1024, out_features=6, bias=True)\n",
       "  (log_std_linear): Linear(in_features=1024, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb Cell 10\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# in-house imports\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msac\u001b[39;00m \u001b[39mimport\u001b[39;00m SAC\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvironment\u001b[39;00m \u001b[39mimport\u001b[39;00m NormilizeActionSpecWrapper, MujocoActionNormalizer, get_flat_obs\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m init_hook_dict, recordtodict_hook, get_kinematics, save_hook_dict\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import tree\n",
    "import argparse\n",
    "import torch\n",
    "from acme import wrappers\n",
    "from dm_control import suite\n",
    "import numpy as np\n",
    "\n",
    "# in-house imports\n",
    "from src.sac import SAC\n",
    "from src.environment import NormilizeActionSpecWrapper, MujocoActionNormalizer, get_flat_obs\n",
    "from src.activations import init_hook_dict, recordtodict_hook, get_kinematics, save_hook_dict\n",
    "from src.bc_net import BCNetworkContinuous\n",
    "\n",
    "GEOM_NAMES = ['ground', 'torso', 'head', 'bthigh', 'bshin', 'bfoot', 'fthigh', 'fshin', 'ffoot']\n",
    "JOINT_NAMES = ['bthigh', 'bshin', 'bfoot', 'fthigh', 'fshin', 'ffoot']\n",
    "ACTUATOR_NAMES = ['bthigh', 'bshin', 'bfoot', 'fthigh', 'fshin', 'ffoot']\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # set up parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_path',\n",
    "                        type=str,\n",
    "                        default='data/bc_model/sac_checkpoint_cheetah_123456_10000',\n",
    "                        help='path to model')\n",
    "    parser.add_argument('--env_name',\n",
    "                        type=str,\n",
    "                        default='HalfCheetah-v4',\n",
    "                        help='name of environment')\n",
    "    parser.add_argument('--num_episodes',\n",
    "                        type=int,\n",
    "                        default=15, help='number of episodes to collect')\n",
    "    parser.add_argument('--save_path',\n",
    "                        type=str,\n",
    "                        default='data/activations/cheetah_123456_10000_bcmodel',\n",
    "                        help='path to save activations')\n",
    "    parser.add_argument('--collect_kinematics',\n",
    "                        type=bool,\n",
    "                        default=True,\n",
    "                        help='whether to collect kinematics')\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # load the environment\n",
    "    if args.env_name == 'HalfCheetah-v4':\n",
    "        env = suite.load(domain_name=\"cheetah\", task_name=\"run\")\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    # add wrappers onto the environment\n",
    "    env = NormilizeActionSpecWrapper(env)\n",
    "    env = MujocoActionNormalizer(environment=env, rescale='clip')\n",
    "    env = wrappers.SinglePrecisionWrapper(env)\n",
    "\n",
    "    # get the dimensionality of the observation_spec after flattening\n",
    "    flat_obs = tree.flatten(env.observation_spec())\n",
    "    # combine all the shapes\n",
    "    obs_dim = sum([item.shape[0] for item in flat_obs])\n",
    "\n",
    "    # initialize the network\n",
    "    network = BCNetworkContinuous(obs_dim, env.action_spec().shape[0])\n",
    "\n",
    "    # load the model\n",
    "    network.load_state_dict(torch.load(args.model_path))\n",
    "\n",
    "    # set to eval mode\n",
    "    network.eval()\n",
    "\n",
    "    # setup hook dict\n",
    "    hook_dict = init_hook_dict(network)\n",
    "    # add hooks\n",
    "    for name, module in network.named_modules():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            module.register_forward_hook(recordtodict_hook(name=name, hook_dict=hook_dict))\n",
    "\n",
    "    # collect activations and kinematics\n",
    "\n",
    "    if args.collect_kinematics:\n",
    "        # get the mapping of the geom names\n",
    "        geom_names_to_idx = {geom_name: idx for idx, geom_name in enumerate(GEOM_NAMES)}\n",
    "        # get the mapping of the joint names\n",
    "        joint_names_to_idx = {joint_name: idx for idx, joint_name in enumerate(JOINT_NAMES)}\n",
    "        # get the mapping of the actuator names\n",
    "        actuator_names_to_idx = {actuator_name: idx for idx, actuator_name in enumerate(ACTUATOR_NAMES)}\n",
    "\n",
    "        idx_to_joint_names = {idx: joint_name for joint_name, idx in joint_names_to_idx.items()}\n",
    "        idx_to_actuator_names = {idx: actuator_name for actuator_name, idx in actuator_names_to_idx.items()}\n",
    "        idx_to_geom_names = {idx: geom_name for geom_name, idx in geom_names_to_idx.items()}\n",
    "\n",
    "        # for recording kinematics\n",
    "        total_kinematic_dict = {\n",
    "            'geom_positions': [],\n",
    "            'joint_angles': [],\n",
    "            'joint_velocities': [],\n",
    "            'actuator_forces': []\n",
    "        }\n",
    "\n",
    "    # run a few episodes just to collect activations\n",
    "    num_episodes_to_run = args.num_episodes\n",
    "\n",
    "    for i in range(num_episodes_to_run):\n",
    "        time_step = env.reset()\n",
    "        episode_reward = 0\n",
    "        while not time_step.last():  # or env.get_termination()\n",
    "            # get the state\n",
    "            state = get_flat_obs(time_step)\n",
    "            # add batch dimension\n",
    "            state = np.expand_dims(state, axis=0)\n",
    "            # sample an action\n",
    "            tensor_state = torch.tensor(state, dtype=torch.float32)\n",
    "            action = network(tensor_state).detach().numpy()\n",
    "            time_step = env.step(action)\n",
    "\n",
    "            if args.collect_kinematics:\n",
    "                # record kinematics\n",
    "                kinematic_dict = get_kinematics(env.physics, GEOM_NAMES, JOINT_NAMES,\n",
    "                                                ACTUATOR_NAMES)\n",
    "                total_kinematic_dict['geom_positions'].append(kinematic_dict['geom_positions'])\n",
    "                total_kinematic_dict['joint_angles'].append(kinematic_dict['joint_angles'])\n",
    "                total_kinematic_dict['joint_velocities'].append(kinematic_dict['joint_velocities'])\n",
    "                total_kinematic_dict['actuator_forces'].append(kinematic_dict['actuator_forces'])\n",
    "            # record reward\n",
    "            episode_reward += time_step.reward\n",
    "        print('Episode: {} Reward: {}'.format(i, episode_reward))\n",
    "\n",
    "    ### optional: save + load the hook_dict\n",
    "\n",
    "    # make folder from args.save_path\n",
    "    os.makedirs(args.save_path, exist_ok=True)\n",
    "\n",
    "    save_path = os.path.join(args.save_path, 'hook_dict.npy')\n",
    "    save_hook_dict(hook_dict, save_path)\n",
    "\n",
    "    if args.collect_kinematics:\n",
    "        # process the kinematics - convert the kinematics to numpy arrays\n",
    "        total_kinematic_dict['geom_positions'] = np.stack(total_kinematic_dict['geom_positions'],\n",
    "                                                          axis=0)  # combine the geom_positions_arr into (t, n, 3)\n",
    "        total_kinematic_dict['joint_angles'] = np.array(total_kinematic_dict['joint_angles'])\n",
    "        total_kinematic_dict['joint_velocities'] = np.array(total_kinematic_dict['joint_velocities'])\n",
    "        total_kinematic_dict['actuator_forces'] = np.array(total_kinematic_dict['actuator_forces'])\n",
    "\n",
    "        # save total_kinematic_dict\n",
    "        save_path = os.path.join(args.save_path, 'kinematics_dict.npy')\n",
    "        np.save(save_path, total_kinematic_dict)\n",
    "\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_hook_dict() missing 1 required positional argument: 'load_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb Cell 8\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m activations\u001b[39m.\u001b[39;49mload_hook_dict()\n",
      "\u001b[0;31mTypeError\u001b[0m: load_hook_dict() missing 1 required positional argument: 'load_path'"
     ]
    }
   ],
   "source": [
    "bc_nonoise_model_activations_path = \"../data/activations/cheetah_123456_10000_nonoise_bcmodel\"\n",
    "bc_nonoise_hooks_path = bc_nonoise_model_activations_path + \"/hook_dict.npy\"\n",
    "\n",
    "\n",
    "activations.load_hook_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_network(network, num_episodes=100, deterministic=True):\n",
    "    \"\"\"\n",
    "    Evaluate a RL agent\n",
    "    :param model: (BaseRLModel object) the RL Agent\n",
    "    :param num_episodes: (int) number of episodes to evaluate it\n",
    "    :return: (float) Mean reward for the last num_episodes\n",
    "    \"\"\"\n",
    "    # This function will only work for a single Environment\n",
    "    all_episode_rewards = []\n",
    "    for i in range(num_episodes):\n",
    "        episode_rewards = []\n",
    "        done = False\n",
    "        obs = env.reset()\n",
    "        while not done:\n",
    "            # _states are only useful when using LSTM policies\n",
    "            action = network(torch.tensor(obs, dtype=torch.float32)).argmax().item()\n",
    "            # here, action, rewards and dones are arrays\n",
    "            # because we are using vectorized env\n",
    "            obs, reward, done, info = env.step([action])\n",
    "            episode_rewards.append(reward)\n",
    "\n",
    "        all_episode_rewards.append(sum(episode_rewards))\n",
    "\n",
    "    mean_episode_reward = np.mean(all_episode_rewards)\n",
    "    print(\"Mean reward:\", mean_episode_reward, \"Num episodes:\", num_episodes)\n",
    "\n",
    "    return mean_episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb Cell 10\u001b[0m in \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         module\u001b[39m.\u001b[39mregister_forward_hook(recordtodict_hook(name\u001b[39m=\u001b[39mname, hook_dict\u001b[39m=\u001b[39mhook_dict_bc))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# # run a few episodes to collect activations\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# num_episodes_to_run = 10\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X10sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X10sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39m#     return mean_episode_reward\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X10sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m evaluate_network(network)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X10sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m loaded_hook_dict_bc \u001b[39m=\u001b[39m compile_hook_dict(hook_dict_bc)\n",
      "\u001b[1;32m/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb Cell 10\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m obs \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# _states are only useful when using LSTM policies\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     action \u001b[39m=\u001b[39m network(torch\u001b[39m.\u001b[39;49mtensor(obs, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32))\u001b[39m.\u001b[39margmax()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# here, action, rewards and dones are arrays\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# because we are using vectorized env\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielson/DSC180B-A08/visualizations/plot_cka.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     obs, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep([action])\n",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "from BCNetwork import BCNetwork\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "network = BCNetwork(24, 6, 1024).to(device)\n",
    "network.load_state_dict(\n",
    "    torch.load(\"../data/bc_models/walker_1024_bc.pt\", map_location=torch.device('cpu'))\n",
    ")\n",
    "\n",
    "# setup hook dict\n",
    "hook_dict_bc = init_hook_dict(network)\n",
    "# add hooks\n",
    "for name, module in network.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        module.register_forward_hook(recordtodict_hook(name=name, hook_dict=hook_dict_bc))\n",
    "\n",
    "\n",
    "# # run a few episodes to collect activations\n",
    "# num_episodes_to_run = 10\n",
    "\n",
    "# for i in range(num_episodes_to_run):\n",
    "#     time_step = env.reset()\n",
    "#     episode_reward = 0\n",
    "#     while not time_step.last():\n",
    "#         # get the state\n",
    "#         state = get_flat_obs(time_step)\n",
    "\n",
    "\n",
    "#         # sample an action\n",
    "        \n",
    "#         def select_action(self, state, evaluate=False):\n",
    "#             state = torch.FloatTensor(state).to(self.device).unsqueeze(0)\n",
    "#             if evaluate is False:\n",
    "#                 action, _, _ = self.policy.sample(state)\n",
    "#             else:\n",
    "#                 _, _, action = self.policy.sample(state)\n",
    "#             return action.detach().cpu().numpy()[0]\n",
    "    \n",
    "#         action = network.select_action(state)\n",
    "\n",
    "\n",
    "#         time_step = env.step(action)\n",
    "\n",
    "#         # record reward\n",
    "#         episode_reward += time_step.reward\n",
    "        \n",
    "#     print('Episode: {} Reward: {}'.format(i, episode_reward))\n",
    "\n",
    "\n",
    "# def evaluate_network(network, num_episodes=10):\n",
    "#     \"\"\"\n",
    "#     Evaluate a RL agent\n",
    "#     :param model: (BaseRLModel object) the RL Agent\n",
    "#     :param num_episodes: (int) number of episodes to evaluate it\n",
    "#     :return: (float) Mean reward for the last num_episodes\n",
    "#     \"\"\"\n",
    "#     all_episode_rewards = []\n",
    "#     for i in range(num_episodes):\n",
    "#         episode_rewards = []\n",
    "#         done = False\n",
    "\n",
    "\n",
    "#         # flat_obs = tree.flatten(env.observation_spec())\n",
    "#         # # combine all the shapes\n",
    "#         # # obs_dim = sum([item.shape[0] for item in flat_obs])\n",
    "#         # obs_dim = 0\n",
    "#         # for i in flat_obs:\n",
    "#         #     try:\n",
    "#         #         obs_dim += i.shape[0]\n",
    "#         #     except IndexError:\n",
    "#         #         obs_dim += 1\n",
    "\n",
    "\n",
    "#         obs = env.reset()\n",
    "        \n",
    "#         while not done:\n",
    "       \n",
    "\n",
    "#             action = network(torch.tensor(list(obs[3].values()), dtype=torch.float32))\n",
    "#             obs, reward, done, info = env.step([action])\n",
    "#             episode_rewards.append(reward)\n",
    "\n",
    "\n",
    "\n",
    "#         all_episode_rewards.append(sum(episode_rewards))\n",
    "\n",
    "#     mean_episode_reward = np.mean(all_episode_rewards)\n",
    "#     print(\"Mean reward:\", mean_episode_reward, \"Num episodes:\", num_episodes)\n",
    "\n",
    "#     return mean_episode_reward\n",
    "\n",
    "evaluate_network(network)\n",
    "\n",
    "loaded_hook_dict_bc = compile_hook_dict(hook_dict_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (3374787892.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [16], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    torch.tensor(list(obs[3].values()), dtype=torch.float32))\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "torch.tensor(list(obs[3].values()), dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(step_type=<StepType.FIRST: 0>, reward=None, discount=None, observation=OrderedDict([('orientations', array([ 0.288338  , -0.9575287 , -0.719978  , -0.6939969 ,  0.8276786 ,\n",
       "       -0.5612024 ,  0.9359683 , -0.35208428,  0.27002808, -0.9628525 ,\n",
       "        0.983658  , -0.18004684,  0.9929495 ,  0.1185384 ], dtype=float32)), ('height', array(1.3, dtype=float32)), ('velocity', array([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('orientations',\n",
       "              array([ 0.288338  , -0.9575287 , -0.719978  , -0.6939969 ,  0.8276786 ,\n",
       "                     -0.5612024 ,  0.9359683 , -0.35208428,  0.27002808, -0.9628525 ,\n",
       "                      0.983658  , -0.18004684,  0.9929495 ,  0.1185384 ], dtype=float32)),\n",
       "             ('height', array(1.3, dtype=float32)),\n",
       "             ('velocity',\n",
       "              array([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fc1': [], 'fc2': [], 'mean_linear': [], 'log_std_linear': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hook_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_hook_dict_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCNetwork(\n",
       "  (fc1): Linear(in_features=24, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (mean_linear): Linear(in_features=1024, out_features=6, bias=True)\n",
       "  (log_std_linear): Linear(in_features=1024, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
