{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MUJOCO_GL=glfw\n",
      "env: PYOPENGL_PLATFORM=\n",
      "env: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
      "Checking that the dm_control installation succeeded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 12:40:36.040 Python[9989:762203] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/jm/y1xn0yjj22v8l8rwlryfjdj00000gn/T/org.python.python.savedState\n",
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib/__init__.py:332: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  version = LooseVersion(match.group(1))\n",
      "/opt/homebrew/lib/python3.10/site-packages/gym/envs/registration.py:250: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for plugin in metadata.entry_points().get(entry_point, []):\n",
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib_inline/config.py:68: DeprecationWarning: InlineBackend._figure_format_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_format_changed(self, name, old, new):\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../src')\n",
    "\n",
    "#Run to install MuJoCo and `dm_control`\n",
    "import distutils.util\n",
    "import subprocess\n",
    "\n",
    "# Use egl locally\n",
    "%env MUJOCO_GL=glfw\n",
    "# Use osmesa on DSMLP\n",
    "# %env MUJOCO_GL=osmesa\n",
    "%env PYOPENGL_PLATFORM=\n",
    "%env PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "\n",
    "print('Checking that the dm_control installation succeeded...')\n",
    "try:\n",
    "    from dm_control import suite\n",
    "    env = suite.load('cartpole', 'swingup')\n",
    "    pixels = env.physics.render()\n",
    "except Exception as e:\n",
    "    raise e from RuntimeError(\n",
    "      'Something went wrong during installation. Check the shell output above '\n",
    "      'for more information.\\n'\n",
    "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
    "      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
    "else:\n",
    "    del pixels, suite\n",
    "\n",
    "\n",
    "#All `dm_control` imports required for this tutorial\n",
    "\n",
    "# The basic mujoco wrapper.\n",
    "from dm_control import mujoco\n",
    "\n",
    "# Access to enums and MuJoCo library functions.\n",
    "from dm_control.mujoco.wrapper.mjbindings import enums\n",
    "from dm_control.mujoco.wrapper.mjbindings import mjlib\n",
    "\n",
    "# PyMJCF\n",
    "from dm_control import mjcf\n",
    "\n",
    "# Composer high level imports\n",
    "from dm_control import composer\n",
    "from dm_control.composer.observation import observable\n",
    "from dm_control.composer import variation\n",
    "\n",
    "# Imports for Composer tutorial example\n",
    "from dm_control.composer.variation import distributions\n",
    "from dm_control.composer.variation import noises\n",
    "from dm_control.locomotion.arenas import floors\n",
    "\n",
    "# Control Suite\n",
    "from dm_control import suite\n",
    "\n",
    "# Run through corridor example\n",
    "from dm_control.locomotion.walkers import cmu_humanoid\n",
    "from dm_control.locomotion.arenas import corridors as corridor_arenas\n",
    "from dm_control.locomotion.tasks import corridors as corridor_tasks\n",
    "\n",
    "# # Soccer\n",
    "# from dm_control.locomotion import soccer\n",
    "\n",
    "# Manipulation\n",
    "from dm_control import manipulation\n",
    "\n",
    "#@title Other imports and helper functions\n",
    "\n",
    "# General\n",
    "import copy\n",
    "import os\n",
    "import itertools\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "\n",
    "# Graphics-related\n",
    "import matplotlib\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import PIL.Image\n",
    "# Internal loading of video libraries.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from torch.optim import Adam\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# try out the wrappers\n",
    "from acme import wrappers\n",
    "from dm_control import suite\n",
    "from acme import wrappers\n",
    "from model import *\n",
    "from utils import *\n",
    "from analysis import *\n",
    "# Soft-Actor-Critic Model\n",
    "from sac import *\n",
    "from replay_memory import *\n",
    "import argparse\n",
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "# Use svg backend for figure rendering\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# Font sizes\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 12\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# Inline video helper function\n",
    "if os.environ.get('COLAB_NOTEBOOK_TEST', False):\n",
    "  # We skip video generation during tests, as it is quite expensive.\n",
    "  display_video = lambda *args, **kwargs: None\n",
    "else:\n",
    "  def display_video(frames, framerate=30):\n",
    "    height, width, _ = frames[0].shape\n",
    "    dpi = 70\n",
    "    orig_backend = matplotlib.get_backend()\n",
    "    matplotlib.use('Agg')  # Switch to headless 'Agg' to inhibit figure rendering.\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(width / dpi, height / dpi), dpi=dpi)\n",
    "    matplotlib.use(orig_backend)  # Switch back to the original backend.\n",
    "    ax.set_axis_off()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_position([0, 0, 1, 1])\n",
    "    im = ax.imshow(frames[0])\n",
    "    def update(frame):\n",
    "      im.set_data(frame)\n",
    "      return [im]\n",
    "    interval = 1000/framerate\n",
    "    anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n",
    "                                   interval=interval, blit=True, repeat=False)\n",
    "    return HTML(anim.to_html5_video())\n",
    "\n",
    "# Seed numpy's global RNG so that cell outputs are deterministic. We also try to\n",
    "# use RandomState instances that are local to a single cell wherever possible.\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "######  Environment wrappers  ####\n",
    "from dm_env import specs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "#@title Loading and simulating a `suite` task{vertical-output: true}\n",
    "\n",
    "# Load the environment\n",
    "# random_state = np.random.RandomState(42)\n",
    "# env = suite.load('hopper', 'stand', task_kwargs={'random': random_state})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from ../data/models/sac_checkpoint_walker_walk_batch512_hidden1024_1123_500\n",
      "linear1 Linear(in_features=24, out_features=1024, bias=True)\n",
      "linear2 Linear(in_features=1024, out_features=1024, bias=True)\n",
      "mean_linear Linear(in_features=1024, out_features=6, bias=True)\n",
      "log_std_linear Linear(in_features=1024, out_features=6, bias=True)\n",
      "Episode: 0 Reward: 926.2218169029802\n",
      "Episode: 1 Reward: 973.897053360939\n",
      "Episode: 2 Reward: 941.6044961474836\n",
      "Episode: 3 Reward: 924.6866829278879\n",
      "Episode: 4 Reward: 953.9642908126116\n",
      "Episode: 5 Reward: 935.403213034384\n",
      "Episode: 6 Reward: 971.1563117355108\n",
      "Episode: 7 Reward: 963.030390009284\n",
      "Episode: 8 Reward: 935.5947681860998\n",
      "Episode: 9 Reward: 948.1791289234534\n"
     ]
    }
   ],
   "source": [
    "# load the environment\n",
    "env = suite.load(domain_name=\"walker\", task_name=\"walk\")\n",
    "# add wrappers onto the environment\n",
    "env = NormilizeActionSpecWrapper(env)\n",
    "env = MujocoActionNormalizer(environment=env, rescale='clip')\n",
    "env = wrappers.SinglePrecisionWrapper(env)\n",
    "\n",
    "\n",
    "\n",
    "class Args:\n",
    "    env_name = 'whatever'\n",
    "    policy = 'Gaussian'\n",
    "    eval = True\n",
    "    gamma = 0.99\n",
    "    tau = 0.005\n",
    "    lr = 0.0003\n",
    "    alpha = 0.2\n",
    "    automatic_entropy_tuning = True\n",
    "    seed = 42\n",
    "    batch_size = 512\n",
    "    num_steps = 1000000\n",
    "    hidden_size = 1024\n",
    "    updates_per_step = 1\n",
    "    start_steps = 10000\n",
    "    target_update_interval = 1\n",
    "    replay_size = 1000000\n",
    "    # use the cuda to speedup\n",
    "    # change back to True\n",
    "    cuda = False\n",
    "\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# get the dimensionality of the observation_spec after flattening\n",
    "flat_obs = tree.flatten(env.observation_spec())\n",
    "# combine all the shapes\n",
    "# obs_dim = sum([item.shape[0] for item in flat_obs])\n",
    "obs_dim = 0\n",
    "for i in flat_obs:\n",
    "    try:\n",
    "        obs_dim += i.shape[0]\n",
    "    except IndexError:\n",
    "        obs_dim += 1\n",
    "\n",
    "# setup agent, using Soft-Actor-Critic Model\n",
    "agent = SAC(obs_dim, env.action_spec(), args)\n",
    "\n",
    "# load checkpoint - UPLOAD YOUR FILE HERE!\n",
    "model_path = '../data/models/sac_checkpoint_walker_walk_batch512_hidden1024_1123_500'\n",
    "agent.load_checkpoint(model_path, evaluate=True)\n",
    "\n",
    "# pull out model\n",
    "model = agent.policy\n",
    "# setup hook dict\n",
    "hook_dict = init_hook_dict(model)\n",
    "# add hooks\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        print(name, module)\n",
    "        module.register_forward_hook(recordtodict_hook(name=name, hook_dict=hook_dict))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run a few episodes just to collect activations\n",
    "num_episodes_to_run = 10\n",
    "\n",
    "for i in range(num_episodes_to_run):\n",
    "    time_step = env.reset()\n",
    "    episode_reward = 0\n",
    "    while not time_step.last():  # or env.get_termination()\n",
    "        # get the state\n",
    "        state = get_flat_obs(time_step)\n",
    "        # sample an action\n",
    "        action = agent.select_action(state)\n",
    "        time_step = env.step(action)\n",
    "\n",
    "        # record reward\n",
    "        episode_reward += time_step.reward\n",
    "    print('Episode: {} Reward: {}'.format(i, episode_reward))\n",
    "\n",
    "\n",
    "loaded_hook_dict = compile_hook_dict(hook_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear1': array([[-6.8759375 , -2.8605616 , -1.444497  , ..., -6.994977  ,\n",
       "         -6.8835955 , -2.4706955 ],\n",
       "        [-6.696662  , -2.6345003 , -2.4793224 , ..., -7.2650023 ,\n",
       "         -7.183061  , -2.8710303 ],\n",
       "        [-6.4651814 , -1.6831925 , -3.2931583 , ..., -7.6537094 ,\n",
       "         -6.6675615 , -2.552099  ],\n",
       "        ...,\n",
       "        [-7.6156006 , -0.540197  ,  1.5038731 , ..., -4.055515  ,\n",
       "         -1.9945788 , -1.2136353 ],\n",
       "        [-7.880992  , -0.8038175 ,  1.2165027 , ..., -4.355412  ,\n",
       "         -2.454401  , -0.81706166],\n",
       "        [-7.591051  ,  0.08079767,  0.6727779 , ..., -2.6759193 ,\n",
       "         -2.1241593 ,  1.2181046 ]], dtype=float32),\n",
       " 'linear2': array([[ -1.709836  ,  -0.44688916,  -4.6141815 , ...,  -1.3566346 ,\n",
       "          -0.69607514,  -0.84597135],\n",
       "        [ -1.5938685 ,  -0.53591204,  -4.1461873 , ...,  -1.2900822 ,\n",
       "          -0.25508887,  -0.72691554],\n",
       "        [ -1.4069092 ,  -0.7056582 ,  -4.2515135 , ...,  -1.2056012 ,\n",
       "           0.23017168,  -0.6264884 ],\n",
       "        ...,\n",
       "        [ -1.1802135 ,  -1.0592124 ,   0.26118773, ...,  -0.9296962 ,\n",
       "          -9.2711315 ,  -0.9273014 ],\n",
       "        [ -1.2221044 ,  -0.87014806,  -0.6060044 , ...,  -0.84787667,\n",
       "          -7.961827  ,  -0.82184005],\n",
       "        [ -1.2841921 ,  -1.2558799 ,   0.94012785, ...,  -0.8870397 ,\n",
       "         -12.096057  ,  -1.0479367 ]], dtype=float32),\n",
       " 'mean_linear': array([[ 0.6557162 ,  0.18083037, -0.06635019, -1.2160137 , -1.1465454 ,\n",
       "          0.09704074],\n",
       "        [ 0.657395  ,  0.27609244, -0.04790933, -0.92423373, -1.1110586 ,\n",
       "         -0.0333012 ],\n",
       "        [ 1.2064267 ,  0.10476121,  0.2154019 , -0.695186  , -0.9359287 ,\n",
       "          0.12686357],\n",
       "        ...,\n",
       "        [-0.82751137,  0.31950945, -0.04641785, -0.19320789,  0.03670925,\n",
       "          0.03979267],\n",
       "        [-0.99479103,  0.8561206 , -0.33217812, -0.23194383,  0.22078107,\n",
       "         -0.0848917 ],\n",
       "        [-1.2712415 ,  0.70082647, -0.16865312, -0.12872288,  0.4252435 ,\n",
       "          0.2647189 ]], dtype=float32),\n",
       " 'log_std_linear': array([[-0.41951725, -0.24287878, -0.33048463, -0.4509772 , -0.40893126,\n",
       "         -0.3181976 ],\n",
       "        [-0.42254543, -0.24637228, -0.3154244 , -0.41079497, -0.3973918 ,\n",
       "         -0.31680334],\n",
       "        [-0.52236485, -0.3455332 , -0.3129393 , -0.42901605, -0.4049927 ,\n",
       "         -0.34997368],\n",
       "        ...,\n",
       "        [-0.44541433, -0.41712907, -0.17642835, -0.2725385 , -0.40033823,\n",
       "         -0.17490263],\n",
       "        [-0.43002367, -0.4774494 , -0.16533114, -0.24140726, -0.40277922,\n",
       "         -0.18451875],\n",
       "        [-0.52010536, -0.45079777, -0.17888726, -0.48293513, -0.4342229 ,\n",
       "         -0.26123774]], dtype=float32)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_hook_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib/axes/_base.py:3270: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  left, right = sorted([left, right], reverse=reverse)\n",
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib/axes/_base.py:3652: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  bottom, top = sorted([bottom, top], reverse=reverse)\n",
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib/axes/_base.py:3652: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  bottom, top = sorted([bottom, top], reverse=reverse)\n",
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib/axes/_base.py:3270: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  left, right = sorted([left, right], reverse=reverse)\n",
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib/axes/_base.py:3652: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  bottom, top = sorted([bottom, top], reverse=reverse)\n",
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib/axes/_base.py:3270: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  left, right = sorted([left, right], reverse=reverse)\n",
      "/opt/homebrew/lib/python3.10/site-packages/matplotlib/axes/_base.py:3652: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  bottom, top = sorted([bottom, top], reverse=reverse)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a558aad0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cka_online = {'activation_1': [],\n",
    "                'activation_2': [],\n",
    "                'cka': []}\n",
    "\n",
    "# get combinations between activations\n",
    "for activation1 in loaded_hook_dict.keys():\n",
    "    for activation2 in loaded_hook_dict.keys():\n",
    "        cka_calc = cka(loaded_hook_dict[activation1], loaded_hook_dict[activation2])\n",
    "        # if activation1 == activation2:\n",
    "        #     cka_calc = 1\n",
    "        cka_online['cka'].append(cka_calc)\n",
    "        cka_online['activation_1'].append(activation1)\n",
    "        cka_online['activation_2'].append(activation2)\n",
    "\n",
    "df = pd.DataFrame(cka_online).pivot('activation_1', 'activation_2', 'cka')\n",
    "sns.heatmap(df, annot=True, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>activation_2</th>\n",
       "      <th>linear1</th>\n",
       "      <th>linear2</th>\n",
       "      <th>log_std_linear</th>\n",
       "      <th>mean_linear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation_1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433177</td>\n",
       "      <td>0.351762</td>\n",
       "      <td>0.178705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear2</th>\n",
       "      <td>0.433177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127477</td>\n",
       "      <td>0.083802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_std_linear</th>\n",
       "      <td>0.351762</td>\n",
       "      <td>0.127477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.198995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_linear</th>\n",
       "      <td>0.178705</td>\n",
       "      <td>0.083802</td>\n",
       "      <td>0.198995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "activation_2     linear1   linear2  log_std_linear  mean_linear\n",
       "activation_1                                                   \n",
       "linear1         1.000000  0.433177        0.351762     0.178705\n",
       "linear2         0.433177  1.000000        0.127477     0.083802\n",
       "log_std_linear  0.351762  0.127477        1.000000     0.198995\n",
       "mean_linear     0.178705  0.083802        0.198995     1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianPolicy(\n",
       "  (linear1): Linear(in_features=24, out_features=1024, bias=True)\n",
       "  (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (mean_linear): Linear(in_features=1024, out_features=6, bias=True)\n",
       "  (log_std_linear): Linear(in_features=1024, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeStep(step_type=<StepType.FIRST: 0>, reward=None, discount=None, observation=OrderedDict([('orientations', array([-0.8400875 , -0.54245096, -0.9939582 ,  0.10975949, -0.43254945,\n",
      "       -0.9016102 , -0.10186333, -0.9947984 , -0.9844075 , -0.17590299,\n",
      "       -0.93594337, -0.35215053, -0.4578623 , -0.8890231 ], dtype=float32)), ('height', array(1.3, dtype=float32)), ('velocity', array([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/y1xn0yjj22v8l8rwlryfjdj00000gn/T/ipykernel_9989/1950259718.py:79: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  action = network(torch.tensor(list(obs[3].values()), dtype=torch.float32))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "not a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [42], line 92\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMean reward:\u001b[39m\u001b[39m\"\u001b[39m, mean_episode_reward, \u001b[39m\"\u001b[39m\u001b[39mNum episodes:\u001b[39m\u001b[39m\"\u001b[39m, num_episodes)\n\u001b[1;32m     90\u001b[0m     \u001b[39mreturn\u001b[39;00m mean_episode_reward\n\u001b[0;32m---> 92\u001b[0m evaluate_network(network)\n\u001b[1;32m     94\u001b[0m loaded_hook_dict_bc \u001b[39m=\u001b[39m compile_hook_dict(hook_dict_bc)\n",
      "Cell \u001b[0;32mIn [42], line 79\u001b[0m, in \u001b[0;36mevaluate_network\u001b[0;34m(network, num_episodes)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mprint\u001b[39m(obs)\n\u001b[1;32m     76\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m---> 79\u001b[0m     action \u001b[39m=\u001b[39m network(torch\u001b[39m.\u001b[39;49mtensor(\u001b[39mlist\u001b[39;49m(obs[\u001b[39m3\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues()), dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32))\n\u001b[1;32m     80\u001b[0m     obs, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep([action])\n\u001b[1;32m     81\u001b[0m     episode_rewards\u001b[39m.\u001b[39mappend(reward)\n",
      "\u001b[0;31mTypeError\u001b[0m: not a sequence"
     ]
    }
   ],
   "source": [
    "from BCNetwork import BCNetwork\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "network = BCNetwork(24, 6, 1024).to(device)\n",
    "network.load_state_dict(\n",
    "    torch.load(\"../data/bc_models/walker_1024_bc.pt\", map_location=torch.device('cpu'))\n",
    ")\n",
    "\n",
    "# setup hook dict\n",
    "hook_dict_bc = init_hook_dict(network)\n",
    "# add hooks\n",
    "for name, module in network.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        module.register_forward_hook(recordtodict_hook(name=name, hook_dict=hook_dict))\n",
    "\n",
    "\n",
    "# # run a few episodes to collect activations\n",
    "# num_episodes_to_run = 10\n",
    "\n",
    "# for i in range(num_episodes_to_run):\n",
    "#     time_step = env.reset()\n",
    "#     episode_reward = 0\n",
    "#     while not time_step.last():\n",
    "#         # get the state\n",
    "#         state = get_flat_obs(time_step)\n",
    "\n",
    "\n",
    "#         # sample an action\n",
    "        \n",
    "#         def select_action(self, state, evaluate=False):\n",
    "#             state = torch.FloatTensor(state).to(self.device).unsqueeze(0)\n",
    "#             if evaluate is False:\n",
    "#                 action, _, _ = self.policy.sample(state)\n",
    "#             else:\n",
    "#                 _, _, action = self.policy.sample(state)\n",
    "#             return action.detach().cpu().numpy()[0]\n",
    "    \n",
    "#         action = network.select_action(state)\n",
    "\n",
    "\n",
    "#         time_step = env.step(action)\n",
    "\n",
    "#         # record reward\n",
    "#         episode_reward += time_step.reward\n",
    "        \n",
    "#     print('Episode: {} Reward: {}'.format(i, episode_reward))\n",
    "\n",
    "\n",
    "def evaluate_network(network, num_episodes=10):\n",
    "    \"\"\"\n",
    "    Evaluate a RL agent\n",
    "    :param model: (BaseRLModel object) the RL Agent\n",
    "    :param num_episodes: (int) number of episodes to evaluate it\n",
    "    :return: (float) Mean reward for the last num_episodes\n",
    "    \"\"\"\n",
    "    all_episode_rewards = []\n",
    "    for i in range(num_episodes):\n",
    "        episode_rewards = []\n",
    "        done = False\n",
    "\n",
    "\n",
    "        # flat_obs = tree.flatten(env.observation_spec())\n",
    "        # # combine all the shapes\n",
    "        # # obs_dim = sum([item.shape[0] for item in flat_obs])\n",
    "        # obs_dim = 0\n",
    "        # for i in flat_obs:\n",
    "        #     try:\n",
    "        #         obs_dim += i.shape[0]\n",
    "        #     except IndexError:\n",
    "        #         obs_dim += 1\n",
    "\n",
    "\n",
    "        obs = env.reset()\n",
    "        print(obs)\n",
    "        \n",
    "        while not done:\n",
    "       \n",
    "\n",
    "            action = network(torch.tensor(list(obs[3].values()), dtype=torch.float32))\n",
    "            obs, reward, done, info = env.step([action])\n",
    "            episode_rewards.append(reward)\n",
    "\n",
    "\n",
    "\n",
    "        all_episode_rewards.append(sum(episode_rewards))\n",
    "\n",
    "    mean_episode_reward = np.mean(all_episode_rewards)\n",
    "    print(\"Mean reward:\", mean_episode_reward, \"Num episodes:\", num_episodes)\n",
    "\n",
    "    return mean_episode_reward\n",
    "\n",
    "evaluate_network(network)\n",
    "\n",
    "loaded_hook_dict_bc = compile_hook_dict(hook_dict_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mtensor(np\u001b[39m.\u001b[39;49marray((obs[\u001b[39m3\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues())), dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "torch.tensor(list(obs[3].values()), dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(step_type=<StepType.FIRST: 0>, reward=None, discount=None, observation=OrderedDict([('orientations', array([ 0.288338  , -0.9575287 , -0.719978  , -0.6939969 ,  0.8276786 ,\n",
       "       -0.5612024 ,  0.9359683 , -0.35208428,  0.27002808, -0.9628525 ,\n",
       "        0.983658  , -0.18004684,  0.9929495 ,  0.1185384 ], dtype=float32)), ('height', array(1.3, dtype=float32)), ('velocity', array([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('orientations',\n",
       "              array([ 0.288338  , -0.9575287 , -0.719978  , -0.6939969 ,  0.8276786 ,\n",
       "                     -0.5612024 ,  0.9359683 , -0.35208428,  0.27002808, -0.9628525 ,\n",
       "                      0.983658  , -0.18004684,  0.9929495 ,  0.1185384 ], dtype=float32)),\n",
       "             ('height', array(1.3, dtype=float32)),\n",
       "             ('velocity',\n",
       "              array([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fc1': [], 'fc2': [], 'mean_linear': [], 'log_std_linear': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hook_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_hook_dict_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCNetwork(\n",
       "  (fc1): Linear(in_features=24, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (mean_linear): Linear(in_features=1024, out_features=6, bias=True)\n",
       "  (log_std_linear): Linear(in_features=1024, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
