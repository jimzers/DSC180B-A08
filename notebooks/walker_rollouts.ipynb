{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a074ac1-6e6f-40d9-8631-6dcb92d2f2aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dm_control...\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/home/yuy004/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/home/yuy004/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/home/yuy004/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/home/yuy004/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/home/yuy004/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/home/yuy004/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "env: MUJOCO_GL=osmesa\n",
      "env: PYOPENGL_PLATFORM=\n",
      "env: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
      "Checking that the dm_control installation succeeded...\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/home/yuy004/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalled dm_control 1.0.8\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_884/4212122258.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../src/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0macme\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrappers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# Soft-Actor-Critic Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "import distutils.util\n",
    "import subprocess\n",
    "# if subprocess.run('nvidia-smi').returncode:\n",
    "#     raise RuntimeError(\n",
    "#       'Cannot communicate with GPU. '\n",
    "#       'Make sure you are using a GPU Colab runtime. '\n",
    "#       'Go to the Runtime menu and select Choose runtime type.')\n",
    "\n",
    "print('Installing dm_control...')\n",
    "!pip install -q dm_control>=1.0.8\n",
    "\n",
    "# Configure dm_control to use the EGL rendering backend (requires GPU)\n",
    "# %env MUJOCO_GL=egl\n",
    "\n",
    "# On DSMLP:\n",
    "%env MUJOCO_GL=osmesa\n",
    "%env PYOPENGL_PLATFORM=\n",
    "%env PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "\n",
    "print('Checking that the dm_control installation succeeded...')\n",
    "try:\n",
    "    from dm_control import suite\n",
    "    env = suite.load('cartpole', 'swingup')\n",
    "    pixels = env.physics.render()\n",
    "except Exception as e:\n",
    "    raise e from RuntimeError(\n",
    "      'Something went wrong during installation. Check the shell output above '\n",
    "      'for more information.\\n'\n",
    "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
    "      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
    "else:\n",
    "    del pixels, suite\n",
    "\n",
    "!echo Installed dm_control $(pip show dm_control | grep -Po \"(?<=Version: ).+\")\n",
    "\n",
    "# %pip -q install git+https://github.com/deepmind/acme.git#egg=dm-acme[jax,tf,envs]\n",
    "# %pip -q install imageio-ffmpeg\n",
    "# %pip -q install gdown\n",
    "\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "# Removed unnecessary generated file\n",
    "! rm -r \"=1.0.8\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tree\n",
    "# plot the activations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from torch.optim import Adam\n",
    "\n",
    "#Run to install MuJoCo and `dm_control`\n",
    "# import this first to resolve the issue.\n",
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "from acme import wrappers\n",
    "from model import *\n",
    "from utils import *\n",
    "# Soft-Actor-Critic Model\n",
    "from sac import *\n",
    "from replay_memory import *\n",
    "\n",
    "# try out the wrappers\n",
    "from acme import wrappers\n",
    "from dm_control import suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f2f851-ad95-423a-a01d-69102ecf48d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Environment wrappers\n",
    "from dm_env import specs\n",
    "\n",
    "\n",
    "# environment wrappers\n",
    "class NormilizeActionSpecWrapper(wrappers.EnvironmentWrapper):\n",
    "    \"\"\"Turn each dimension of the actions into the range of [-1, 1].\"\"\"\n",
    "\n",
    "    def __init__(self, environment):\n",
    "        super().__init__(environment)\n",
    "\n",
    "        action_spec = environment.action_spec()\n",
    "        self._scale = action_spec.maximum - action_spec.minimum\n",
    "        self._offset = action_spec.minimum\n",
    "\n",
    "        minimum = action_spec.minimum * 0 - 1.\n",
    "        maximum = action_spec.minimum * 0 + 1.\n",
    "        self._action_spec = specs.BoundedArray(\n",
    "            action_spec.shape,\n",
    "            action_spec.dtype,\n",
    "            minimum,\n",
    "            maximum,\n",
    "            name=action_spec.name)\n",
    "\n",
    "    def _from_normal_actions(self, actions):\n",
    "        actions = 0.5 * (actions + 1.0)  # a_t is now in the range [0, 1]\n",
    "        # scale range to [minimum, maximum]\n",
    "        return actions * self._scale + self._offset\n",
    "\n",
    "    def step(self, action):\n",
    "        action = self._from_normal_actions(action)\n",
    "        return self._environment.step(action)\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "\n",
    "class MujocoActionNormalizer(wrappers.EnvironmentWrapper):\n",
    "    \"\"\"Rescale actions to [-1, 1] range for mujoco physics engine.\n",
    "\n",
    "    For control environments whose actions have bounded range in [-1, 1], this\n",
    "      adaptor rescale actions to the desired range. This allows actor network to\n",
    "      output unscaled actions for better gradient dynamics.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, environment, rescale='clip'):\n",
    "        super().__init__(environment)\n",
    "        self._rescale = rescale\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Rescale actions to [-1, 1] range before stepping wrapped environment.\"\"\"\n",
    "        if self._rescale == 'tanh':\n",
    "            scaled_actions = tree.map_structure(np.tanh, action)\n",
    "        elif self._rescale == 'clip':\n",
    "            scaled_actions = tree.map_structure(lambda a: np.clip(a, -1., 1.), action)\n",
    "        else:\n",
    "            raise ValueError('Unrecognized scaling option: %s' % self._rescale)\n",
    "        return self._environment.step(scaled_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "656d547c-0951-4486-87a8-d52d7903b9fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'suite' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_884/2430018772.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"walker\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"walk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# add wrappers onto the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormilizeActionSpecWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMujocoActionNormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'clip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'suite' is not defined"
     ]
    }
   ],
   "source": [
    "# load the environment\n",
    "env = suite.load(domain_name=\"walker\", task_name=\"walk\")\n",
    "# add wrappers onto the environment\n",
    "env = NormilizeActionSpecWrapper(env)\n",
    "env = MujocoActionNormalizer(environment=env, rescale='clip')\n",
    "env = wrappers.SinglePrecisionWrapper(env)\n",
    "\n",
    "\n",
    "class Args:\n",
    "    env_name = 'whatever'\n",
    "    policy = 'Gaussian'\n",
    "    eval = True\n",
    "    gamma = 0.99\n",
    "    tau = 0.005\n",
    "    lr = 0.0003\n",
    "    alpha = 0.2\n",
    "    automatic_entropy_tuning = True\n",
    "    seed = 42\n",
    "    batch_size = 512\n",
    "    num_steps = 1000000\n",
    "    hidden_size = 1024\n",
    "    updates_per_step = 1\n",
    "    start_steps = 10000\n",
    "    target_update_interval = 1\n",
    "    replay_size = 1000000\n",
    "    cuda = True\n",
    "\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# get the dimensionality of the observation_spec after flattening\n",
    "print(env.observation_spec())\n",
    "flat_obs = tree.flatten(env.observation_spec())\n",
    "#flat_obs = flat_obs[1:]\n",
    "print(flat_obs[1:])\n",
    "# combine all the shapes\n",
    "#obs_dim = sum([item.shape[0] for item in flat_obs])\n",
    "obs_dim = 0\n",
    "for i in flat_obs:\n",
    "    try:\n",
    "        obs_dim += i.shape[0]\n",
    "    except IndexError:\n",
    "        obs_dim += 1\n",
    "# setup agent, using Soft-Actor-Critic Model\n",
    "agent = SAC(obs_dim, env.action_spec(), args)\n",
    "# load checkpoint - UPLOAD YOUR FILE HERE!\n",
    "model_path = 'sac_checkpoint_walker_walk_batch512_hidden1024_1123_500'\n",
    "agent.load_checkpoint(model_path, evaluate=True)\n",
    "\n",
    "# pull out model\n",
    "model = agent.policy\n",
    "# setup hook dict\n",
    "hook_dict = init_hook_dict(model)\n",
    "# add hooks\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        module.register_forward_hook(recordtodict_hook(name=name, hook_dict=hook_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbce47db-f3a0-4855-9f88-037a619ab639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array(shape=(), dtype=dtype('float32'), name='height'),\n",
       " Array(shape=(14,), dtype=dtype('float32'), name='orientations'),\n",
       " Array(shape=(9,), dtype=dtype('float32'), name='velocity')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "219f0bb3-2d30-4cce-ae47-1fbc03599cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Reward: 956.8336200937629\n",
      "Episode: 11 Reward: 932.5251256353222\n",
      "Episode: 21 Reward: 953.6426235754043\n",
      "Episode: 31 Reward: 982.009455576539\n",
      "Episode: 41 Reward: 939.4821482943371\n"
     ]
    }
   ],
   "source": [
    "# run a few episodes just to collect activations\n",
    "num_episodes_to_run = 42\n",
    "\n",
    "rewards = []\n",
    "states = []\n",
    "actions = []\n",
    "for i in range(num_episodes_to_run):\n",
    "    time_step = env.reset()\n",
    "    episode_reward = 0\n",
    "    \n",
    "    while not time_step.last():  # or env.get_termination()\n",
    "        # get the state\n",
    "        #state = get_flat_obs(time_step)\n",
    "        flat_obs = tree.flatten(time_step.observation)\n",
    "        flat_obs[0] = flat_obs[0].reshape(-1,1)[0]\n",
    "        state = np.concatenate(flat_obs)\n",
    "        # sample an action\n",
    "        action = agent.select_action(state)\n",
    "        time_step = env.step(action)\n",
    "\n",
    "        # record reward\n",
    "        time_step_reward = time_step.reward\n",
    "        rewards.append(time_step_reward)\n",
    "        episode_reward += time_step_reward\n",
    "        \n",
    "        #record states and actions\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "    if i % 10 == 0:\n",
    "        print('Episode: {} Reward: {}'.format(i+1, episode_reward))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
