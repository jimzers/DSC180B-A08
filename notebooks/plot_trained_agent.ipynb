{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../src')\n",
    "\n",
    "#@title Run to install MuJoCo and `dm_control`\n",
    "import distutils.util\n",
    "import subprocess\n",
    "\n",
    "# print('Installing dm_control...')\n",
    "!pip install -q dm_control==1.0.8\n",
    "!pip install imageio-ffmpeg\n",
    "\n",
    "# Use egl locally\n",
    "# %env MUJOCO_GL=egl\n",
    "# Use osmesa on DSMLP\n",
    "%env MUJOCO_GL=osmesa\n",
    "%env PYOPENGL_PLATFORM=\n",
    "%env PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "\n",
    "print('Checking that the dm_control installation succeeded...')\n",
    "try:\n",
    "    from dm_control import suite\n",
    "    env = suite.load('cartpole', 'swingup')\n",
    "    pixels = env.physics.render()\n",
    "except Exception as e:\n",
    "    raise e from RuntimeError(\n",
    "      'Something went wrong during installation. Check the shell output above '\n",
    "      'for more information.\\n'\n",
    "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
    "      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
    "else:\n",
    "    del pixels, suite\n",
    "\n",
    "\n",
    "#@title All `dm_control` imports required for this tutorial\n",
    "\n",
    "# The basic mujoco wrapper.\n",
    "from dm_control import mujoco\n",
    "\n",
    "# Access to enums and MuJoCo library functions.\n",
    "from dm_control.mujoco.wrapper.mjbindings import enums\n",
    "from dm_control.mujoco.wrapper.mjbindings import mjlib\n",
    "\n",
    "# PyMJCF\n",
    "from dm_control import mjcf\n",
    "\n",
    "# Composer high level imports\n",
    "from dm_control import composer\n",
    "from dm_control.composer.observation import observable\n",
    "from dm_control.composer import variation\n",
    "\n",
    "# Imports for Composer tutorial example\n",
    "from dm_control.composer.variation import distributions\n",
    "from dm_control.composer.variation import noises\n",
    "from dm_control.locomotion.arenas import floors\n",
    "\n",
    "# Control Suite\n",
    "from dm_control import suite\n",
    "\n",
    "# Run through corridor example\n",
    "from dm_control.locomotion.walkers import cmu_humanoid\n",
    "from dm_control.locomotion.arenas import corridors as corridor_arenas\n",
    "from dm_control.locomotion.tasks import corridors as corridor_tasks\n",
    "\n",
    "# # Soccer\n",
    "# from dm_control.locomotion import soccer\n",
    "\n",
    "# Manipulation\n",
    "from dm_control import manipulation\n",
    "\n",
    "#@title Other imports and helper functions\n",
    "\n",
    "# General\n",
    "import copy\n",
    "import os\n",
    "import itertools\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "\n",
    "# Graphics-related\n",
    "import matplotlib\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import PIL.Image\n",
    "# Internal loading of video libraries.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from torch.optim import Adam\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# try out the wrappers\n",
    "from acme import wrappers\n",
    "from dm_control import suite\n",
    "from acme import wrappers\n",
    "from model import *\n",
    "from utils import *\n",
    "# Soft-Actor-Critic Model\n",
    "from sac import *\n",
    "from replay_memory import *\n",
    "import argparse\n",
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "# Use svg backend for figure rendering\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# Font sizes\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 12\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# Inline video helper function\n",
    "if os.environ.get('COLAB_NOTEBOOK_TEST', False):\n",
    "  # We skip video generation during tests, as it is quite expensive.\n",
    "  display_video = lambda *args, **kwargs: None\n",
    "else:\n",
    "  def display_video(frames, framerate=30):\n",
    "    height, width, _ = frames[0].shape\n",
    "    dpi = 70\n",
    "    orig_backend = matplotlib.get_backend()\n",
    "    matplotlib.use('Agg')  # Switch to headless 'Agg' to inhibit figure rendering.\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(width / dpi, height / dpi), dpi=dpi)\n",
    "    matplotlib.use(orig_backend)  # Switch back to the original backend.\n",
    "    ax.set_axis_off()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_position([0, 0, 1, 1])\n",
    "    im = ax.imshow(frames[0])\n",
    "    def update(frame):\n",
    "      im.set_data(frame)\n",
    "      return [im]\n",
    "    interval = 1000/framerate\n",
    "    anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n",
    "                                   interval=interval, blit=True, repeat=False)\n",
    "    return HTML(anim.to_html5_video())\n",
    "\n",
    "# Seed numpy's global RNG so that cell outputs are deterministic. We also try to\n",
    "# use RandomState instances that are local to a single cell wherever possible.\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "######  Environment wrappers  ####\n",
    "from dm_env import specs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "#@title Loading and simulating a `suite` task{vertical-output: true}\n",
    "\n",
    "# Load the environment\n",
    "# random_state = np.random.RandomState(42)\n",
    "# env = suite.load('hopper', 'stand', task_kwargs={'random': random_state})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# Simulate episode with random actions\n",
    "def visualize(duration=10, save=False, name\"vids.mp4\"):\n",
    "    frames = []\n",
    "    ticks = []\n",
    "    rewards = []\n",
    "    observations = []\n",
    "\n",
    "    spec = env.action_spec()\n",
    "    time_step = env.reset()\n",
    "    \n",
    "    curr_time = -1\n",
    "\n",
    "    while env.physics.data.time < duration and not time_step.last():\n",
    "        state = get_flat_obs(time_step)\n",
    "        action = agent.select_action(state)\n",
    "        time_step = env.step(action)\n",
    "\n",
    "        camera0 = env.physics.render(camera_id=0, height=400, width=400)\n",
    "        camera1 = env.physics.render(camera_id=1, height=400, width=400)\n",
    "        frames.append(np.hstack((camera0, camera1)))\n",
    "        rewards.append(time_step.reward)\n",
    "        observations.append(copy.deepcopy(time_step.observation))\n",
    "        ticks.append(env.physics.data.time)\n",
    "        time = env.physics.data.time\n",
    "        if int(time) != curr_time:\n",
    "            curr_time = int(time)\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Current Rendering Progress: {curr_time}s / {duration}s\")\n",
    "    print(\"Rendering Complete!\")\n",
    "    html_video = display_video(frames, framerate=1./env.control_timestep())\n",
    "\n",
    "    # Show video and plot reward and observations\n",
    "    num_sensors = len(time_step.observation)\n",
    "\n",
    "    _, ax = plt.subplots(1 + num_sensors, 1, sharex=True, figsize=(4, 8))\n",
    "    ax[0].plot(ticks, rewards)\n",
    "    ax[0].set_ylabel('reward')\n",
    "    ax[-1].set_xlabel('time')\n",
    "\n",
    "    for i, key in enumerate(time_step.observation):\n",
    "        data = np.asarray([observations[j][key] for j in range(len(observations))])\n",
    "        ax[i+1].plot(ticks, data, label=key)\n",
    "        ax[i+1].set_ylabel(key)\n",
    "    if save:\n",
    "        save_video(frames, video_name=f\"{name}.mp4\")\n",
    "        plt.savefig(f\"{name}.png\", dpi=200)\n",
    "\n",
    "    return html_video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fccc94c",
   "metadata": {},
   "source": [
    "# Visulize Online Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd81f2f",
   "metadata": {},
   "source": [
    "Below is a listing of all training parameter you need to load for a specific task/agent to visualize.\n",
    "1. `checkpoints/sac_checkpoint_hopper_hop1001_2100`\n",
    "```python\n",
    "# load the environment\n",
    "env = suite.load(domain_name=\"hopper\", task_name=\"hop\")\n",
    "# add wrappers onto the environment\n",
    "env = NormilizeActionSpecWrapper(env)\n",
    "env = MujocoActionNormalizer(environment=env, rescale='clip')\n",
    "env = wrappers.SinglePrecisionWrapper(env)\n",
    "class Args:\n",
    "    env_name = 'whatever'\n",
    "    policy = 'Gaussian'\n",
    "    eval = True\n",
    "    gamma = 0.99\n",
    "    tau = 0.005\n",
    "    lr = 0.0003\n",
    "    alpha = 0.2\n",
    "    automatic_entropy_tuning = True\n",
    "    seed = 42\n",
    "    batch_size = 256\n",
    "    num_steps = 1000000\n",
    "    hidden_size = 1024\n",
    "    updates_per_step = 1\n",
    "    start_steps = 10000\n",
    "    target_update_interval = 1\n",
    "    replay_size = 1000000\n",
    "    # use the cuda to speedup\n",
    "    cuda = True\n",
    "```\n",
    "\n",
    "2. `checkpoints/sac_checkpoint_hopper_404_2000`\n",
    "```python\n",
    "# load the environment\n",
    "env = suite.load(domain_name=\"hopper\", task_name=\"stand\")\n",
    "# add wrappers onto the environment\n",
    "env = NormilizeActionSpecWrapper(env)\n",
    "env = MujocoActionNormalizer(environment=env, rescale='clip')\n",
    "env = wrappers.SinglePrecisionWrapper(env)\n",
    "class Args:\n",
    "    env_name = 'whatever'\n",
    "    policy = 'Gaussian'\n",
    "    eval = True\n",
    "    gamma = 0.99\n",
    "    tau = 0.005\n",
    "    lr = 0.0003\n",
    "    alpha = 0.2\n",
    "    automatic_entropy_tuning = True\n",
    "    seed = 42\n",
    "    batch_size = 256\n",
    "    num_steps = 1000000\n",
    "    hidden_size = 256\n",
    "    updates_per_step = 1\n",
    "    start_steps = 10000\n",
    "    target_update_interval = 1\n",
    "    replay_size = 1000000\n",
    "    # use the cuda to speedup\n",
    "    cuda = True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bede59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the environment\n",
    "env = suite.load(domain_name=\"walker\", task_name=\"walk\")\n",
    "# add wrappers onto the environment\n",
    "env = NormilizeActionSpecWrapper(env)\n",
    "env = MujocoActionNormalizer(environment=env, rescale='clip')\n",
    "env = wrappers.SinglePrecisionWrapper(env)\n",
    "\n",
    "\n",
    "class Args:\n",
    "    env_name = 'whatever'\n",
    "    policy = 'Gaussian'\n",
    "    eval = True\n",
    "    gamma = 0.99\n",
    "    tau = 0.005\n",
    "    lr = 0.0003\n",
    "    alpha = 0.2\n",
    "    automatic_entropy_tuning = True\n",
    "    seed = 42\n",
    "    batch_size = 512\n",
    "    num_steps = 1000000\n",
    "    hidden_size = 1024\n",
    "    updates_per_step = 1\n",
    "    start_steps = 10000\n",
    "    target_update_interval = 1\n",
    "    replay_size = 1000000\n",
    "    # use the cuda to speedup\n",
    "    cuda = True\n",
    "\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# get the dimensionality of the observation_spec after flattening\n",
    "flat_obs = tree.flatten(env.observation_spec())\n",
    "# combine all the shapes\n",
    "# obs_dim = sum([item.shape[0] for item in flat_obs])\n",
    "obs_dim = 0\n",
    "for i in flat_obs:\n",
    "    try:\n",
    "        obs_dim += i.shape[0]\n",
    "    except IndexError:\n",
    "        obs_dim += 1\n",
    "\n",
    "# setup agent, using Soft-Actor-Critic Model\n",
    "agent = SAC(obs_dim, env.action_spec(), args)\n",
    "# load checkpoint - UPLOAD YOUR FILE HERE!\n",
    "model_path = '../data/models/sac_checkpoint_walker_walk_batch512_hidden1024_1123_500'\n",
    "agent.load_checkpoint(model_path, evaluate=True)\n",
    "\n",
    "# pull out model\n",
    "model = agent.policy\n",
    "# setup hook dict\n",
    "hook_dict = init_hook_dict(model)\n",
    "# add hooks\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        module.register_forward_hook(recordtodict_hook(name=name, hook_dict=hook_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be9763e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "vids = visualize(duration=10, save=True, name=\"online_walker\")\n",
    "display(vids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b498c33",
   "metadata": {},
   "source": [
    "# Visulize Offline (BC) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f99f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BCNetwork import BCNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f1ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb8b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = BCNetwork(24, 6, 1024).to(device)\n",
    "network.load_state_dict(\n",
    "    torch.load(\"../data/bc_models/walker_1024_bc.pt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def visualize_bc(duration=10, save=False, name=\"vids.mp4\"):\n",
    "    frames = []\n",
    "    ticks = []\n",
    "    rewards = []\n",
    "    observations = []\n",
    "\n",
    "    spec = env.action_spec()\n",
    "    time_step = env.reset()\n",
    "    \n",
    "    curr_time = -1\n",
    "\n",
    "    while env.physics.data.time < duration and not time_step.last():\n",
    "        state = get_flat_obs(time_step)\n",
    "        # use bc network\n",
    "        action = network(torch.tensor(state), device=device)\n",
    "        time_step = env.step(action.cpu().detach().numpy())\n",
    "\n",
    "        camera0 = env.physics.render(camera_id=0, height=400, width=400)\n",
    "        camera1 = env.physics.render(camera_id=1, height=400, width=400)\n",
    "        frames.append(np.hstack((camera0, camera1)))\n",
    "        rewards.append(time_step.reward)\n",
    "        observations.append(copy.deepcopy(time_step.observation))\n",
    "        ticks.append(env.physics.data.time)\n",
    "        time = env.physics.data.time\n",
    "        if int(time) != curr_time:\n",
    "            curr_time = int(time)\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Current Rendering Progress: {curr_time}s / {duration}s\")\n",
    "    print(\"Rendering Complete!\")\n",
    "    html_video = display_video(frames, framerate=1./env.control_timestep())\n",
    "\n",
    "    # Show video and plot reward and observations\n",
    "    num_sensors = len(time_step.observation)\n",
    "\n",
    "    _, ax = plt.subplots(1 + num_sensors, 1, sharex=True, figsize=(4, 8))\n",
    "    ax[0].plot(ticks, rewards)\n",
    "    ax[0].set_ylabel('reward')\n",
    "    ax[-1].set_xlabel('time')\n",
    "\n",
    "    for i, key in enumerate(time_step.observation):\n",
    "        data = np.asarray([observations[j][key] for j in range(len(observations))])\n",
    "        ax[i+1].plot(ticks, data, label=key)\n",
    "        ax[i+1].set_ylabel(key)\n",
    "    if save:\n",
    "        save_video(frames, video_name=f\"{name}.mp4\")\n",
    "        plt.savefig(f\"{name}.png\", dpi=200)\n",
    "\n",
    "    return html_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a9eef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "vids = visualize_bc(duration=10, save=True, name=\"BC_walker\")\n",
    "display(vids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a417296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b28c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c788073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840bcef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
